# CIRIS Telemetry Taxonomy - Complete Guide

## Overview
CIRIS has **136 metrics** currently implemented (target: 250) across multiple collection mechanisms and storage patterns.

## 1. Collection Mechanisms (HOW metrics are gathered)

### PULL Metrics (82 total)
**Definition**: Metrics computed on-demand when requested, not stored
- **get_metrics()**: New standard public interface (via BaseService)
- **_collect_custom_metrics()**: Override point for service-specific metrics
- **get_telemetry()**: Legacy method being phased out

**Current Implementation**:
- 35 metrics from get_telemetry() methods
- 47 metrics from _collect_metrics/_collect_custom_metrics

**Characteristics**:
- Real-time computation
- No storage overhead
- Available via `/metrics` API endpoints
- Perfect for current state (health, uptime, counts)

### PUSH Metrics (19 total)
**Definition**: Metrics actively recorded to Time Series Database (TSDB)
- **record_metric()**: Direct TSDB storage
- **memorize_metric()**: Graph + TSDB storage (dual persistence)

**Current Implementation**:
- 18 metrics via record_metric()
- 1 metric via memorize_metric()

**Characteristics**:
- Historical data retention
- Queryable over time ranges
- Storage overhead
- Perfect for events, costs, resource usage

### Handler Metrics (44 total)
**Definition**: Automatic metrics from action processing
- Generated by ActionDispatcher
- Tracks all handler invocations, completions, errors

**Characteristics**:
- Automatic collection
- PUSH storage (TSDB)
- No service implementation needed

## 2. Service Hierarchy (WHERE metrics come from)

### Core Services (21 total)
```
Graph Services (6)
├── memory_service        ✅ has _collect_custom_metrics (5 metrics)
├── config_service        ✅ has _collect_custom_metrics (2 metrics)
├── telemetry_service     ❌ needs _collect_custom_metrics
├── audit_service         ❌ needs _collect_custom_metrics
├── incident_management   ❌ needs conversion from get_telemetry
└── tsdb_consolidation    ❌ needs _collect_custom_metrics

Infrastructure Services (7)
├── time_service          ❌ needs _collect_custom_metrics
├── shutdown_service      ❌ needs _collect_custom_metrics
├── initialization       ❌ needs _collect_custom_metrics
├── authentication       ❌ needs _collect_custom_metrics
├── resource_monitor     ❌ needs _collect_custom_metrics
├── database_maintenance ❌ needs _collect_custom_metrics
└── secrets              ❌ needs _collect_custom_metrics

Governance Services (4)
├── wise_authority       ❌ needs _collect_custom_metrics
├── adaptive_filter      ❌ needs _collect_custom_metrics
├── visibility           ❌ needs _collect_custom_metrics
└── self_observation     ❌ needs _collect_custom_metrics

Runtime Services (3)
├── llm_service          ❌ needs _collect_custom_metrics
├── runtime_control      ❌ needs _collect_custom_metrics
└── task_scheduler       ❌ needs _collect_custom_metrics

Tool Services (1)
└── secrets_tool         ✅ has _collect_custom_metrics (1 metric)
```

### Adapters (Runtime-added services)
- **DiscordAdapter**: Adds 3 services at runtime
- **APIAdapter**: Adds 3 services at runtime
- **CLIAdapter**: Adds 1 service at runtime

### Message Buses (6 total)
- **LLMBus**: 7 PUSH metrics (tokens, costs, latency)
- **MemoryBus**: Routes to memory service metrics
- **CommunicationBus**: Routes to adapter metrics
- **WiseBus**: Routes to wise authority metrics
- **ToolBus**: Routes to tool service metrics
- **RuntimeControlBus**: Routes to runtime control metrics

## 3. Metric Types (WHAT is measured)

### Service Health Metrics (Base)
Every service inherits from BaseService:
- `uptime_seconds`: Time since service start
- `request_count`: Total requests handled
- `error_count`: Total errors encountered
- `error_rate`: Ratio of errors to requests
- `healthy`: Binary health indicator (1.0 or 0.0)

### Resource Metrics
- Memory usage (MB)
- CPU usage (percentage)
- Database size (MB)
- Cache sizes
- Queue depths

### Business Metrics
- Token usage (input/output/total)
- Cost tracking (cents)
- Environmental impact (carbon_grams, energy_kwh)
- Handler success/failure rates
- Action selection counts

### Graph Metrics
- Node counts by type
- Edge counts
- Storage size
- Query performance

## 4. Storage & Availability

### NONE (Pull metrics)
- No storage, computed on-demand
- Zero persistence overhead
- Real-time accuracy

### TSDB (Push metrics)
- Stored in time_series_data table
- 6-hour raw retention
- Consolidated for long-term storage
- Queryable via `/metrics/history` endpoints

### Graph (Special metrics)
- memorize_metric() stores in both graph AND TSDB
- Provides dual persistence
- Enables correlation analysis

## 5. Implementation Patterns

### Adding Metrics to a Service

```python
class MyService(BaseService):
    def _collect_custom_metrics(self) -> Dict[str, float]:
        """Override to add service-specific metrics."""
        metrics = super()._collect_custom_metrics()

        # Add your metrics
        metrics.update({
            "queue_depth": float(len(self.queue)),
            "cache_hit_rate": self.cache_hits / max(1, self.cache_attempts),
            "processing_time_ms": self.last_processing_time * 1000,
        })

        return metrics
```

### Metric Naming Convention
```
{service_name}.{category}.{specific_metric}

Examples:
- llm.tokens.input
- memory.graph.node_count
- config.cache.hit_rate
- wise_authority.decisions.deferred
```

## 6. Current Status & Gap Analysis

**Current**: 136 metrics
- 82 PULL (get_metrics + _collect_custom_metrics)
- 19 PUSH (record_metric + memorize_metric)
- 44 Handler (automatic)

**Target**: 250 metrics
**Gap**: 114 metrics

**Implementation Plan**:
1. Add ~12 metrics to each of the 17 services without _collect_custom_metrics
2. This gives us: 17 × 12 = 204 additional metrics
3. Total would be: 136 + 204 = 340 metrics (exceeding target)

## 7. Best Practices

1. **Use PULL for state**: Current values, counts, rates
2. **Use PUSH for events**: Costs, errors, completions
3. **Inherit from BaseService**: Get 5 free metrics
4. **Override _collect_custom_metrics**: Add service-specific metrics
5. **Avoid psutil**: Only resource_monitor should use it
6. **Follow naming convention**: service.category.metric
7. **Keep metrics lightweight**: Don't compute expensive metrics in PULL
8. **Document metric meaning**: Add comments explaining what each metric measures

## 8. Access Patterns

### Via API
- `/api/{agent}/v1/metrics` - Current PULL metrics
- `/api/{agent}/v1/metrics/history` - Historical PUSH metrics
- `/api/{agent}/v1/telemetry` - Aggregated telemetry

### Via Services
- `TelemetryAggregator.get_telemetry()` - Collects from all services
- `service.get_metrics()` - Direct service metrics
- `telemetry_service.record_metric()` - Store PUSH metric

### Via Graph
- `memory_service.memorize_metric()` - Dual storage
- `memory_service.recall_timeseries()` - Query historical
