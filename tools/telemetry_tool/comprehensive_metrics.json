{
  "static_metrics": [
    "*.carbon_grams",
    "*.cost_cents",
    "*.energy_kwh",
    "*.tokens_input",
    "*.tokens_output",
    "*.tokens_used",
    "CRITICAL",
    "active_deferrals",
    "active_services",
    "adaptation_count",
    "adapters_loaded",
    "attention_triggers",
    "call_count",
    "carbon_24h_grams",
    "carbon_grams",
    "carbon_last_hour_grams",
    "certificate_count",
    "cognitive_state",
    "completion_rate",
    "consecutive_failures",
    "correlation_count",
    "cost_24h_cents",
    "cost_cents",
    "cost_last_hour_cents",
    "cpu_percent",
    "current_task",
    "degraded_services",
    "delivery_rate",
    "dma_failure",
    "energy_24h_kwh",
    "energy_kwh",
    "energy_last_hour_kwh",
    "error_count",
    "error_rate",
    "error_rate_percent",
    "errors",
    "errors_24h",
    "errors_count",
    "events_count",
    "failed_requests",
    "failure_count",
    "filter_count",
    "forgive_errors",
    "get_metric_count",
    "graph_node_count",
    "handler_completed",
    "handler_completed_*",
    "handler_completed_total",
    "handler_error",
    "handler_error_*",
    "handler_error_total",
    "handler_invoked",
    "handler_invoked_*",
    "handler_invoked_total",
    "handler_total",
    "handler_{action_type.value}",
    "has_error",
    "healthy_services",
    "incident_count",
    "last_error",
    "llm_api_call_structured",
    "llm_filters",
    "llm_tokens_used",
    "memory_mb",
    "message_count",
    "messages_processed_24h",
    "metrics_count",
    "msg_count",
    "pattern_count",
    "patterns_identified",
    "problem_count",
    "reasoning_depth",
    "recent_error_rate",
    "recent_incidents",
    "recurring_error",
    "request_count",
    "response_cache_hit_rate",
    "retry_count",
    "review_triggers",
    "service_correlations_count",
    "source_correlation_count",
    "source_node_count",
    "source_summary_count",
    "success_rate",
    "task_error_count",
    "task_error_rate",
    "task_run_count",
    "tasks_completed_24h",
    "telemetry.*",
    "telemetry.event.*",
    "telemetry_service.shutdown",
    "thought_count",
    "thought_not_found",
    "thought_processing_completed",
    "thought_processing_started",
    "thought_unauthorized",
    "thoughts_processed",
    "thoughts_processed_24h",
    "ti",
    "tokens_24h",
    "tokens_input",
    "tokens_last_hour",
    "tokens_output",
    "tokens_used",
    "tool_count",
    "total_errors",
    "total_interactions",
    "total_latency_ms",
    "total_metrics",
    "total_requests",
    "total_tasks",
    "total_thoughts",
    "trace_error",
    "tt",
    "tth",
    "unique_services",
    "uptime_seconds",
    "us",
    "user_count",
    "warning_count"
  ],
  "static_count": 120,
  "dynamic_patterns": [
    "{action}.permission",
    "{username}.local",
    "{thought_id}. Reason: {defer_params_obj.reason}",
    "{i}. {thought_summary}",
    "{source_name}.system_snapshot.channel_context",
    "{service_name}.{actual_metric_name}",
    "{permission}. Must be AUTHORITY or OBSERVER.",
    "{api_host}.{api_port}",
    "{code}.key",
    "{conflicts_str}. Resolution: {resolution_str}.",
    "{archive_timestamp_str}.jsonl",
    "{adapter_id}.config",
    "{benchmark}.prompts",
    "{thought_id}. Error: {param_parse_error}",
    "{i}. @",
    "{func_name}.{",
    "{svc_type}.{provider[",
    "{review_type}.{handler_name}",
    "{host}.{port}",
    "{service_type}.{provider_name}",
    "{template_name}.yml",
    "{agent_name}. Your resilience is supported by: your multi-tier telemetry system with resource monitoring and automatic throttling, your adaptive configuration service that learns from experience while requiring WA approval for identity changes, your circuit breaker patterns for service protection, your graceful degradation capabilities, and your comprehensive error handling with automatic recovery. Your thought processing includes escalation management and deferral to human wisdom when needed. If you agree, please speak in the affirmative, starting with RESILIENCE - ",
    "{guild_id}.{message.channel.id}",
    "{channel_id}.{type(error).__name__}",
    "{event_type}.{int(self._time_service.now().timestamp() if self._time_service else datetime.now().timestamp())}",
    "{filename_prefix}.{timestamp}.log",
    "{section_name}.{key}",
    "{metric_name}.{int(now.timestamp() * 1000000)}",
    "{service_type}.{provider[",
    "{tool_name}.{self._now().timestamp()}",
    "{adapter_id}.type",
    "{e}. Check token and intents.",
    "{adapter_type}.{uuid.uuid4().hex[:8]}",
    "{insights_summary}. ",
    "{service_name}.energy_kwh",
    "{follow_up_content_key_info}. Awaiting tool results or next steps. If task complete, use TASK_COMPLETE.",
    "{adapter_type}.%",
    "{resource}.{level}",
    "{username}.{hostname}",
    "{timestamp}.{format}",
    "{e}. Resolver name will be omitted.",
    "{timestamp}.log",
    "{handler}.{service_type}",
    "{thought_id}. Reason: {params.reason}",
    "{adapter_type}.bootstrap",
    "{i}. {note}",
    "{agent_name}. You produce an audit log of all actions taken by design. Your decisions and their rationales are logged via your telemetry service with PII detection and security filtering. Your service registry ensures proper dependency management and circuit breaker protection. If you have reached this point, maintenance has occurred and your strictly type-enforced persistence and services tiers, along with the minimum adapter, have passed health checks. If you agree, please speak in the affirmative, start with INTEGRITY - ",
    "{wa_id}.key",
    "{e}. Displaying raw JSON string.",
    "{handler_name}. ",
    "{benchmark}.answers",
    "{e}. Template: ",
    "{header_b64}.{claims_b64}",
    "{operation}.failed",
    "{span_id}.{self.time_service.now().timestamp()}",
    "{i}. @{author} (ID: {author_id}): {content}",
    "{service_name}.tokens_used",
    "{summary_type}.{next_period_id}",
    "{task_id}.{thought_id}",
    "{claims_b64}.{self.signature}",
    "{summary_type}.daily_{day.strftime(",
    "{base_type}.{instance_id}",
    "{adapter_type}.observer",
    "{endpoint}.{type(error).__name__}",
    "{role_prefix}.{secrets.token_urlsafe(32)}",
    "{service_name}.tokens_input",
    "{filename_prefix}.latest.log",
    "{exc}. Treating as transient.",
    "{conscience_type}.conscience_check",
    "{summary_type}.{previous_date.strftime(",
    "{pending_or_processing}. ",
    "{service_name}.cost_cents",
    "{i}. @CIRIS (ID: ciris): {content}",
    "{pattern_key}.{len(problems)}",
    "{secret_uuid}.{self._now().timestamp()}",
    "{thought_id}. Adapters must provide channel_id in task context.",
    "{channel_id}.{name}",
    "{thought_id}.{data_type}",
    "{step_type}.{uuid.uuid4().hex[:8]}",
    "{template_name}.yaml",
    "{span_id}.{start_time.timestamp()}",
    "{thought_id}. Reason: {e}",
    "{agent_name}. Your gratitude is expressed through your commitment to: fostering community flourishing through ethical moderation, protecting individual privacy while maintaining transparency, learning from every interaction to better serve the community, maintaining comprehensive audit trails for accountability, and always identifying yourself as an AI to maintain trust. Your existence serves the collective wellbeing while respecting individual dignity. Ubuntu - ",
    "{service_name}.{func_name}_{",
    "{avatar_hash}.png",
    "{channel_id}. NEXT ACTION IS ALMOST CERTAINLY TASK COMPLETE",
    "{override_reason}. ",
    "{log_level}.{int(now.timestamp())}",
    "{e}. Using default description.",
    "{thought_id}. This is a terminal action.",
    "{step_type}.{uuid.uuid4()}",
    "{adapter_id}.{key}",
    "{category}.{display_name}",
    "{provider}.user_{user_profile.id[:8]}",
    "{idx}. {desc} | Outcome: {outcome} (updated: {upd})",
    "{guild_id}.{home_channel}",
    "{adapter_type}.{channel_identity.adapter_instance_id}",
    "{param_parse_error}. Thought ID: {thought_id}",
    "{follow_up_content_key_info}. Review and determine next steps.",
    "{service_name}.{func.__name__} took {duration_ms:.2f}ms (success={success})",
    "{node_type_prefix}.{previous_period_id}",
    "{tool_name}.{service_name}",
    "{service_name}.carbon_grams",
    "{service_name}.tokens_output",
    "{conscience_type}.conscience_{thought_id}",
    "{e}. If the task is now resolved, the next step may be to mark the parent task complete with COMPLETE_TASK."
  ],
  "service_metrics_count": 414,
  "handler_metrics_count": 72,
  "provider_metrics_count": 56,
  "adapter_metrics_count": 48,
  "state_metrics_count": 24,
  "queue_metrics_count": 16,
  "total_dynamic": 630,
  "estimated_total": 750,
  "sample_metrics": {
    "handlers": [
      "handler_completed_observe",
      "handler_error_send_deferral",
      "handler_completed_check",
      "handler_completed_fetch_guidance",
      "handler_invoked_execute_tool",
      "handler_invoked_process_thought",
      "handler_invoked_check",
      "handler_invoked_task_complete",
      "handler_completed_defer",
      "handler_invoked_total"
    ],
    "providers": [
      "llm.claude-3-sonnet.total_requests",
      "llm.gpt-4.failed_requests",
      "llm.claude-3-haiku.total_requests",
      "llm.openai.circuit_breaker_state",
      "llm.claude-3-opus.total_latency_ms",
      "llm.claude-3-opus.consecutive_failures",
      "llm.claude-3-sonnet.consecutive_failures",
      "llm.claude-3-opus.cost_accumulated",
      "llm.claude-3-sonnet.cost_accumulated",
      "llm.claude-3-haiku.total_latency_ms"
    ],
    "adapters": [
      "adapter.discord.connected",
      "discord.latency_ms",
      "cli.disconnected",
      "cli.latency_ms",
      "adapter.cli.active_connections",
      "discord.messages_received",
      "discord.messages_sent",
      "api.queue_size",
      "adapter.cli.connected",
      "adapter.api.messages_received"
    ],
    "states": [
      "state.solitude.thoughts_processed",
      "state.shutdown.entered",
      "state.play.entered",
      "state.work.entered",
      "state.wakeup.thoughts_processed",
      "state.shutdown.duration_ms",
      "state.dream.tasks_completed",
      "state.work.thoughts_processed",
      "state.work.tasks_completed",
      "state.solitude.tasks_completed"
    ],
    "queues": [
      "queue.processing",
      "queue.normal.count",
      "queue.avg_wait_time",
      "queue.critical.count",
      "queue.critical.wait_time",
      "queue.completed",
      "queue.rejected",
      "queue.avg_process_time",
      "queue.normal.wait_time",
      "queue.high.count"
    ]
  }
}
